{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"genome analysis analysis of genetic variants flowchart TD DATA[Variant Data] --> PD[Prompt Design] AC[Analysis Criteria] --> PD[Prompt Design] PD --> GS[Gene Search] PD --> VI[Variant Information] PD --> DS[Database Search] GS --> R[Combined Results] VI --> R[Combined Results] DS --> R[Combined Results] R --> F[Final Report] F --> |Feedback| R Project Organization \u251c\u2500\u2500 LICENSE <- Open-source license if one is chosen \u251c\u2500\u2500 Makefile <- Makefile with convenience commands like `make data` or `make train` \u251c\u2500\u2500 README.md <- The top-level README for developers using this project. \u251c\u2500\u2500 data \u2502 \u251c\u2500\u2500 external <- Data from third party sources. \u2502 \u251c\u2500\u2500 interim <- Intermediate data that has been transformed. \u2502 \u251c\u2500\u2500 processed <- The final, canonical data sets for modeling. \u2502 \u2514\u2500\u2500 raw <- The original, immutable data dump. \u2502 \u251c\u2500\u2500 docs <- A default mkdocs project; see mkdocs.org for details \u2502 \u251c\u2500\u2500 models <- Trained and serialized models, model predictions, or model summaries \u2502 \u251c\u2500\u2500 notebooks <- Jupyter notebooks. Naming convention is a number (for ordering), \u2502 the creator's initials, and a short `-` delimited description, e.g. \u2502 `1.0-jqp-initial-data-exploration`. \u2502 \u251c\u2500\u2500 pyproject.toml <- Project configuration file with package metadata for gen_analysis_module \u2502 and configuration for tools like black \u2502 \u251c\u2500\u2500 references <- Data dictionaries, manuals, and all other explanatory materials. \u2502 \u251c\u2500\u2500 reports <- Generated analysis as HTML, PDF, LaTeX, etc. \u2502 \u2514\u2500\u2500 figures <- Generated graphics and figures to be used in reporting \u2502 \u251c\u2500\u2500 requirements.txt <- The requirements file for reproducing the analysis environment, e.g. \u2502 generated with `pip freeze > requirements.txt` \u2502 \u251c\u2500\u2500 setup.cfg <- Configuration file for flake8 \u2502 \u2514\u2500\u2500 gen_analysis_module <- Source code for use in this project. \u2502 \u251c\u2500\u2500 __init__.py <- Makes gen_analysis_module a Python module \u2502 \u251c\u2500\u2500 data <- Scripts to download or generate data \u2502 \u2514\u2500\u2500 make_dataset.py \u2502 \u251c\u2500\u2500 features <- Scripts to turn raw data into features for modeling \u2502 \u2514\u2500\u2500 build_features.py \u2502 \u251c\u2500\u2500 models <- Scripts to train models and then use trained models to make \u2502 \u2502 predictions \u2502 \u251c\u2500\u2500 predict_model.py \u2502 \u2514\u2500\u2500 train_model.py \u2502 \u2514\u2500\u2500 visualization <- Scripts to create exploratory and results oriented visualizations \u2514\u2500\u2500 visualize.py Project README Overview This project involves a genetic analysis workflow, utilizing scripts and modules to process and analyze genetic data. The following sections detail the contents of the project, including scripts, modules, and their respective functionalities. Directory Structure contrib/ This folder contains utility scripts and additional resources to aid users in executing analyses. 20241004_quickrun_gen_analysisV2.sh : A bash script that activates a conda environment and lists files in the raw data directory. It prompts the user for confirmation before running the gen_analysis.py script, which processes genetic data and generates reports in Markdown and DOCX formats. pandoc.sh : A simple script example for converting Markdown files to DOCX using Pandoc. rm_request_open_terminal.sh : A script to submit an interactive job to a SLURM scheduler, providing access to a terminal for executing commands. gen_analysis_module/ This module includes the core functionality for data processing and analysis. config.py : Configures project directories and loads environment variables. Sets paths for raw, processed, and external data. dataset.py : Contains a command-line interface for processing datasets, with customizable input and output paths. features.py : Similar to dataset.py , this script generates features from processed datasets and allows for path customization. gen_analysis.py : The main analysis script that reads TSV files, processes genetic variant information, and generates elaborated descriptions using the OpenAI API. plots.py : A placeholder for future plotting functionalities, designed to generate visual representations of the processed data. tests/ This directory includes test cases to ensure the functionality of the project. test_gen_analysis.py : Uses pytest to validate the existence of TSV files in the test data directory and tests the core functions for getting file paths and generating elaboration from prompts. data/ Contains various test cases in the form of TSV files used for validating the functionality of the scripts. Notable files include: empty.tsv extracol.tsv header.tsv malformed.tsv missingcol.tsv test_file_1.tsv test_file_2.tsv Usage To run the analysis, follow these steps: 1. Navigate to the contrib directory. 2. Execute the 20241004_quickrun_gen_analysisV2.sh script. 3. Confirm the continuation when prompted. 4. The analysis will be executed, generating outputs in the specified formats. SLURM Job Management The project includes guidelines for submitting jobs to SLURM, with a focus on managing job numbers and ensuring the correct environment is activated for execution. Additional Notes Ensure that the necessary environment variables for the OpenAI API are set in the .env file. For any issues related to the SLURM job environment, refer to the provided commands and troubleshooting steps.","title":"Home"},{"location":"#genome-analysis","text":"analysis of genetic variants flowchart TD DATA[Variant Data] --> PD[Prompt Design] AC[Analysis Criteria] --> PD[Prompt Design] PD --> GS[Gene Search] PD --> VI[Variant Information] PD --> DS[Database Search] GS --> R[Combined Results] VI --> R[Combined Results] DS --> R[Combined Results] R --> F[Final Report] F --> |Feedback| R","title":"genome analysis"},{"location":"#project-organization","text":"\u251c\u2500\u2500 LICENSE <- Open-source license if one is chosen \u251c\u2500\u2500 Makefile <- Makefile with convenience commands like `make data` or `make train` \u251c\u2500\u2500 README.md <- The top-level README for developers using this project. \u251c\u2500\u2500 data \u2502 \u251c\u2500\u2500 external <- Data from third party sources. \u2502 \u251c\u2500\u2500 interim <- Intermediate data that has been transformed. \u2502 \u251c\u2500\u2500 processed <- The final, canonical data sets for modeling. \u2502 \u2514\u2500\u2500 raw <- The original, immutable data dump. \u2502 \u251c\u2500\u2500 docs <- A default mkdocs project; see mkdocs.org for details \u2502 \u251c\u2500\u2500 models <- Trained and serialized models, model predictions, or model summaries \u2502 \u251c\u2500\u2500 notebooks <- Jupyter notebooks. Naming convention is a number (for ordering), \u2502 the creator's initials, and a short `-` delimited description, e.g. \u2502 `1.0-jqp-initial-data-exploration`. \u2502 \u251c\u2500\u2500 pyproject.toml <- Project configuration file with package metadata for gen_analysis_module \u2502 and configuration for tools like black \u2502 \u251c\u2500\u2500 references <- Data dictionaries, manuals, and all other explanatory materials. \u2502 \u251c\u2500\u2500 reports <- Generated analysis as HTML, PDF, LaTeX, etc. \u2502 \u2514\u2500\u2500 figures <- Generated graphics and figures to be used in reporting \u2502 \u251c\u2500\u2500 requirements.txt <- The requirements file for reproducing the analysis environment, e.g. \u2502 generated with `pip freeze > requirements.txt` \u2502 \u251c\u2500\u2500 setup.cfg <- Configuration file for flake8 \u2502 \u2514\u2500\u2500 gen_analysis_module <- Source code for use in this project. \u2502 \u251c\u2500\u2500 __init__.py <- Makes gen_analysis_module a Python module \u2502 \u251c\u2500\u2500 data <- Scripts to download or generate data \u2502 \u2514\u2500\u2500 make_dataset.py \u2502 \u251c\u2500\u2500 features <- Scripts to turn raw data into features for modeling \u2502 \u2514\u2500\u2500 build_features.py \u2502 \u251c\u2500\u2500 models <- Scripts to train models and then use trained models to make \u2502 \u2502 predictions \u2502 \u251c\u2500\u2500 predict_model.py \u2502 \u2514\u2500\u2500 train_model.py \u2502 \u2514\u2500\u2500 visualization <- Scripts to create exploratory and results oriented visualizations \u2514\u2500\u2500 visualize.py","title":"Project Organization"},{"location":"#project-readme","text":"","title":"Project README"},{"location":"#overview","text":"This project involves a genetic analysis workflow, utilizing scripts and modules to process and analyze genetic data. The following sections detail the contents of the project, including scripts, modules, and their respective functionalities.","title":"Overview"},{"location":"#directory-structure","text":"","title":"Directory Structure"},{"location":"#contrib","text":"This folder contains utility scripts and additional resources to aid users in executing analyses. 20241004_quickrun_gen_analysisV2.sh : A bash script that activates a conda environment and lists files in the raw data directory. It prompts the user for confirmation before running the gen_analysis.py script, which processes genetic data and generates reports in Markdown and DOCX formats. pandoc.sh : A simple script example for converting Markdown files to DOCX using Pandoc. rm_request_open_terminal.sh : A script to submit an interactive job to a SLURM scheduler, providing access to a terminal for executing commands.","title":"contrib/"},{"location":"#gen_analysis_module","text":"This module includes the core functionality for data processing and analysis. config.py : Configures project directories and loads environment variables. Sets paths for raw, processed, and external data. dataset.py : Contains a command-line interface for processing datasets, with customizable input and output paths. features.py : Similar to dataset.py , this script generates features from processed datasets and allows for path customization. gen_analysis.py : The main analysis script that reads TSV files, processes genetic variant information, and generates elaborated descriptions using the OpenAI API. plots.py : A placeholder for future plotting functionalities, designed to generate visual representations of the processed data.","title":"gen_analysis_module/"},{"location":"#tests","text":"This directory includes test cases to ensure the functionality of the project. test_gen_analysis.py : Uses pytest to validate the existence of TSV files in the test data directory and tests the core functions for getting file paths and generating elaboration from prompts.","title":"tests/"},{"location":"#data","text":"Contains various test cases in the form of TSV files used for validating the functionality of the scripts. Notable files include: empty.tsv extracol.tsv header.tsv malformed.tsv missingcol.tsv test_file_1.tsv test_file_2.tsv","title":"data/"},{"location":"#usage","text":"To run the analysis, follow these steps: 1. Navigate to the contrib directory. 2. Execute the 20241004_quickrun_gen_analysisV2.sh script. 3. Confirm the continuation when prompted. 4. The analysis will be executed, generating outputs in the specified formats.","title":"Usage"},{"location":"#slurm-job-management","text":"The project includes guidelines for submitting jobs to SLURM, with a focus on managing job numbers and ensuring the correct environment is activated for execution.","title":"SLURM Job Management"},{"location":"#additional-notes","text":"Ensure that the necessary environment variables for the OpenAI API are set in the .env file. For any issues related to the SLURM job environment, refer to the provided commands and troubleshooting steps.","title":"Additional Notes"}]}